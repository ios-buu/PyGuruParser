
### 2019-03-12
* URI层数 -- 所有平均值，单一文档中的平均值，不同版本下URI层数的变化
* API资源数量 -- 颗粒度：文档、全部、谓词
* HTTP谓词的频率及分布 -- 颗粒度：文档、全部、API资源数量
* 数据层数 -- 取所有文档不同版本下的数据层数变化趋势
* 数据关联关系 -- 取不同文档下的数据关联情况

* 演化的数据分析 -> 预测API以后的发展 -> 评估标准
* 不同版本下，成正比例的API文档的信息统计 -> 资源模型 -> 设计规范

* 形成一个软件有两部分功能
* 第一部分，识别某文件夹下的API文档（或者通过网络抓包爬取API），存入数据库，并提供对库中所有API进行数据分析、预测发展的功能。

* 第二部分，查看某一文档的评估情况以及使用图形化的方式展现出文档的结果（如果可行的话可以动态操作）



















### 2019-03-13
* URI 层数 -> 预测未来URI会如何变化

* API资源数量 -> 预测未来URI会以什么趋势发展

* HTTP谓词的频率及分布 -> 最大最小颗粒度分析

* 数据层数 -> 预测未来数据

* OpenAPI的官方标签使用频率 -> 最大最小，不同版本的增加趋势

* 数据关联关系 -> 待定，算法过于复杂

* info表不足以做数据分析，要根据paths字段进行拆分，需要以API为单位单独存储。






















### 2019-03-23

#### 统计信息

##### 一天

* URI 层数 -> 总数、平均值、众数、最大值、最小值、表格（x层数，y个数）
* * HTTP谓词的频率及分布 -> 最多值、最少值、占比、饼状图（谓词分布）
* 数据层数 -> 平均值、众数、最大值、最小值、表格（x层数，y个数）
* 版本统计-> 平均值、众数、表格（x版本数量，y文档个数）
* 请求约束数量 -> 总数、平均值、众数、表格（x请求约束数量，字段数量），表格（x请求约束数量，文档数量）
##### 两天
* GET请求Request参数的数量 -> 包含参数的api总数、所有参数的api的请求参数数量的平均值、一个uri最多参数有多少个、柱状图（x参数数量、y uri个数）、表格（x位置，y参数数量）
* Request位置 -> 位置的总数、哪个位置的参数最多、哪个位置的参数最少、叠柱状图（x位置、y 当前位置下资源数量的分布）

##### 三天

* API资源数量 -> 总数、以文档为单位的资源数量的平均值、以文档为单位的api数量的众数、所有文档中资源最多的那个文档的资源数量、最少的资源数量、表格（x资源数，y每个文档中的资源数量）

* API数量 -> 总数、以文档为单位api数量的平均值、以文档为单位api数量的众数、所有文档中资源最多的那个文档的api数量、最少的api数量、表格（x资源数，y每个文档的api数量）
* API端点数量 -> 总数、以文档为单位端点数量的平均值、以文档为单位端点数量的众数、所有文档中资源最多的那个文档的端点数量、最少的哪个端点数量、表格（x资源数，y每个文档的端点数量）

* HTTP谓词的频率及分布 -> 一个uri里包含的谓词最多值、最少值、柱状图（x 谓词数量，y当前谓词数量下的uri数量）

#### 趋势

##### 四天

`不同版本的文档中：x始终是版本号`

* URI层数 y->uri总数（柱状图+折线图）
* API资源数量 y->资源总数（柱状图+折线图）
* API数量 y->api总数（柱状图+折线图）
* API端点数量  y->端点总数（柱状图+折线图）
##### 五天
* 谓词占比 y->各个谓词的总数及占比（叠柱状图）

* Response数据层数 y->每层的总数及占比（叠柱状图）

* 请求约束数量 y->每档约束数量的总数及占比（叠柱状图）

* Request参数数量 y->没档参数数量的总数及占比（叠柱状图）

* 不同位置的参数数量 y->不同位置的参数数量及占比（叠柱状图）

