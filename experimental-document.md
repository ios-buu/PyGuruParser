
## 2019-03-12
* URI层数 -- 所有平均值，单一文档中的平均值，不同版本下URI层数的变化
* API资源数量 -- 颗粒度：文档、全部、谓词
* HTTP谓词的频率及分布 -- 颗粒度：文档、全部、API资源数量
* 数据层数 -- 取所有文档不同版本下的数据层数变化趋势
* 数据关联关系 -- 取不同文档下的数据关联情况

* 演化的数据分析 -> 预测API以后的发展 -> 评估标准
* 不同版本下，成正比例的API文档的信息统计 -> 资源模型 -> 设计规范

* 形成一个软件有两部分功能
* 第一部分，识别某文件夹下的API文档（或者通过网络抓包爬取API），存入数据库，并提供对库中所有API进行数据分析、预测发展的功能。

* 第二部分，查看某一文档的评估情况以及使用图形化的方式展现出文档的结果（如果可行的话可以动态操作）



















## 2019-03-13
* URI 层数 -> 预测未来URI会如何变化

* API资源数量 -> 预测未来URI会以什么趋势发展

* HTTP谓词的频率及分布 -> 最大最小颗粒度分析

* 数据层数 -> 预测未来数据

* OpenAPI的官方标签使用频率 -> 最大最小，不同版本的增加趋势

* 数据关联关系 -> 待定，算法过于复杂

* info表不足以做数据分析，要根据paths字段进行拆分，需要以API为单位单独存储。






















## 2019-03-23

#### 统计信息

##### 一天

* URI 层数 -> 总数、平均值、众数、最大值、最小值、表格（x层数，y个数）
* * HTTP谓词的频率及分布 -> 最多值、最少值、占比、饼状图（谓词分布）
* 数据层数 -> 平均值、众数、最大值、最小值、表格（x层数，y个数）
* 版本统计-> 平均值、众数、表格（x版本数量，y文档个数）
* 请求约束数量 -> 总数、平均值、众数、表格（x请求约束数量，字段数量），表格（x请求约束数量，文档数量）
##### 两天
* GET请求Request参数的数量 -> 包含参数的api总数、所有参数的api的请求参数数量的平均值、一个uri最多参数有多少个、柱状图（x参数数量、y uri个数）、表格（x位置，y参数数量）
* Request位置 -> 位置的总数、哪个位置的参数最多、哪个位置的参数最少、叠柱状图（x位置、y 当前位置下资源数量的分布）

##### 三天

* API资源数量 -> 总数、以文档为单位的资源数量的平均值、以文档为单位的api数量的众数、所有文档中资源最多的那个文档的资源数量、最少的资源数量、表格（x资源数，y每个文档中的资源数量）

* API数量 -> 总数、以文档为单位api数量的平均值、以文档为单位api数量的众数、所有文档中资源最多的那个文档的api数量、最少的api数量、表格（x资源数，y每个文档的api数量）
* API端点数量 -> 总数、以文档为单位端点数量的平均值、以文档为单位端点数量的众数、所有文档中资源最多的那个文档的端点数量、最少的哪个端点数量、表格（x资源数，y每个文档的端点数量）

* HTTP谓词的频率及分布 -> 一个uri里包含的谓词最多值、最少值、柱状图（x 谓词数量，y当前谓词数量下的uri数量）

#### 趋势

##### 四天

`不同版本的文档中：x始终是版本号`

* URI层数 y->uri总数（柱状图+折线图）

* API资源数量 y->资源总数（柱状图+折线图）

* API数量 y->api总数（柱状图+折线图）

* API端点数量  y->端点总数（柱状图+折线图）

##### 五天

* 谓词占比 y->各个谓词的总数及占比（叠柱状图）

* Response数据层数 y->每层的总数及占比（叠柱状图）

* 请求约束数量 y->每档约束数量的总数及占比（叠柱状图）

* Request参数数量 y->没档参数数量的总数及占比（叠柱状图）

* 不同位置的参数数量 y->不同位置的参数数量及占比（叠柱状图）

## 2019-04-15

* 如何知道两个API之间是先后版本关系？

除了swagger.yaml的所在目录以外，如果两个项目见有先后版本关系，该如何处理。

我的想法是，通过git，github中一定有master的push记录，而python可以控制git拉取到每次commit时的代码，在本地一步一步回退，然后记录有修改过的文件，记为一个版本，这样就能记录下不同版本，甚至同版本的修改趋势。

* 如果是不同文档的修改，比如azure.com这样的，可以识别路径，可是如果域名都替换了，应该找什么办法替换？

看了一下已有数据，可以用关键的字段组合判断是否为同一文档

#### 关于上面的数据统计完成情况

趋势方面的统计，有些复杂，需要后面整理后再做，其余数据统计除了版本统计、约束数量、数据层数外其余的所有统计都已完成。

趋势的计划如下

#### 元数据
##### `不同版本的文档中：x是不同间隔下的api（这里只统计至少有两个版本及以上的api文档）`

* URI层数 y->uri总数（散点图）

* API资源数量 y->资源总数（散点图）

* API端点数量  y->端点总数（散点图）

* 谓词数量 y->各个谓词的总数及占比（散点图*2）

* Response数据层数 y->每层的总数及占比（散点图*2）

* 请求约束数量 y->每档约束数量的总数及占比（散点图*2）

* Request参数数量 y->没档参数数量的总数及占比（散点图*2）

* 不同位置的参数数量 y->不同位置的参数数量及占比（散点图*2）


### 趋势（未来预测）
##### `不同版本的文档中：x是不同间隔下的api（这里只统计至少有两个版本及以上的api文档）`

* URI层数 y->uri总数（散点图）

* API资源数量 y->资源总数（散点图）

* API端点数量  y->端点总数（散点图）

* 谓词数量 y->各个谓词的总数及占比（散点图*2）

* Response数据层数 y->每层的总数及占比（散点图*2）

* 请求约束数量 y->每档约束数量的总数及占比（散点图*2）

* Request参数数量 y->没档参数数量的总数及占比（散点图*2）

* 不同位置的参数数量 y->不同位置的参数数量及占比（散点图*2）

之前两条线：

* 演化的数据分析 -> 预测API以后的发展 -> 评估标准
* 不同版本下，api资源的关联关系 -> 资源模型 -> 设计规范

目前第一条已经基本完成主要工作，目前还缺少不同版本下的api数据及其图表展示部分

第二条是在第一条的基础上进行的工作，目前的想法是根据资源的关联关系，使用元数据的字段以及数据添加时的字段进行匹配，不过这个依赖相关的设计以及文档编写时的严谨逻辑。

不过，目前数据库里有10万条请求数据，有些多。。。